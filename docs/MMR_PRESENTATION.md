# MMR 알고리즘 적용 및 파라미터 최적화

발표 자료 (2025-12-01)

---

## 📋 간단 요약 (30초)

```
1. 문제: 순수 벡터 검색은 유사한 표현만 반복
   예: "주말에", "주말엔", "주말에" → 단조로움

2. 해결: MMR 알고리즘 적용 (λ=0.9)
   의미적 유사도 90% + 표현 다양성 10%

3. 결과: 의미는 유지하면서 표현 다양화
   평균 유사도 -0.5% (거의 유지)
   표현 다양성 +14.3% (개선)
```

---

## 📊 상세 발표 (2분)

### 1️⃣ 문제 정의

**순수 벡터 검색의 한계**

```
쿼리: "주말에 뭐 할 거야?"

검색 결과:
1. 주말에 어디 가십니까
2. 주말동안 한 게 없네
3. 주말에 해야될듯 합니다
4. 주말에 하려고,.
5. 주말에 들어오십니까
6. 주말엔 나도 안 간다
7. 주말 배송도 하느라
   ↓
7개가 모두 "주말"로 시작 (70% 일치)
→ 의미는 유사하지만 표현이 단조로움
```

---

### 2️⃣ 해결 방법: MMR 알고리즘

**MMR (Maximal Marginal Relevance)**

```
공식:
MMR Score = λ × Similarity - (1-λ) × max(Similarity_selected)
            ↑                  ↑
        의미적 유사도         이미 선택된 것과의 유사도
```

**파라미터 의미:**
- λ = 1.0: 순수 유사도 (다양성 0%)
- λ = 0.9: 의미 90% + 다양성 10% ← **최적값**
- λ = 0.8: 의미 80% + 다양성 20%
- λ = 0.7: 의미 70% + 다양성 30%

---

### 3️⃣ 파라미터 최적화 실험

**테스트 쿼리**: "주말에 뭐 할 거야?"

| λ 값 | 평균 유사도 | 유사도 변화 | 표현 다양성 | 평가 |
|------|-----------|-----------|-----------|------|
| 1.0 (순수) | 0.5924 | - | 70% 일치 | 기준 |
| **0.9** | **0.5878** | **-0.8%** | **60% 일치** | **✅ 최적** |
| 0.8 | 0.5574 | -5.9% | 30% 일치 | ⚠️ 과도 |
| 0.7 | 0.5273 | -11.0% | 10% 일치 | ❌ 의미손실 |

**결론: λ = 0.9가 최적**
- 의미적 유사도 거의 유지 (-0.8%)
- 표현 다양성은 14.3% 개선
- 균형잡힌 접근

---

### 4️⃣ 실제 결과 비교

```
λ = 1.0 (순수 벡터):
1. [0.6731] 주말에 어디 가십니까
2. [0.6287] 주말동안 한 게 없네
3. [0.6215] 주말에 해야될듯 합니다
4. [0.6145] 주말에 하려고,.
5. [0.6060] 주말에 들어오십니까
6. [0.5964] 주말엔 나도 안 간다
7. [0.5735] 주말 배송도 하느라
   → 7개가 "주말"로 시작 (단조로움)

λ = 0.9 (MMR):
1. [0.6731] 주말에 어디 가십니까
2. [0.6287] 주말동안 한 게 없네
3. [0.6215] 주말에 해야될듯 합니다
4. [0.6145] 주말에 하려고,.
5. [0.5412] 저녁으로 할까?         ← 다른 시간 표현
6. [0.5392] 매주 정해진 날마다...   ← 다른 시간 표현
7. [0.6060] 주말에 들어오십니까
   → 6개가 "주말"로 시작 (표현 다양화)
```

**개선 효과:**
- 의미적 유사도: 0.5924 → 0.5878 (-0.8%)
- "주말" 일치율: 70% → 60% (-14.3%)
- 결론: 의미는 유지하면서 표현만 다양화 ✅

---

### 5️⃣ 핵심 인사이트

#### Q: 왜 1536차원 벡터를 쓰는데 앞글자가 같으면 유사하다고 나오나?

**A: 잘못된 해석입니다.**

- ❌ 잘못: "앞글자가 같아서 유사하다고 판단"
- ✅ 올바름: "의미적으로 유사한 문장들이 우연히 같은 단어로 시작"

**예시:**
```
"주말에 뭐 할 거야?" 쿼리에:
- "주말에 어디 가십니까" → 의미적으로 매우 유사 (0.6731)
- "주말동안 한 게 없네" → 의미적으로 유사 (0.6287)
- "주말에 해야될듯 합니다" → 의미적으로 유사 (0.6215)

이들은 모두 "주말 계획/활동"에 대한 내용이므로
의미적으로 진짜 유사한 것이 맞습니다.
```

**첫 글자 일치는:**
- 한국어 특성상 자연스러운 현상
- "주말에", "주말엔", "주말동안" → 모두 의미적으로도 유사
- 1536차원 벡터는 정상 작동 중 ✅
- MMR은 표현 다양성을 위한 도구

---

### 6️⃣ 람다(λ) 값이 높을수록 좋은 이유

**람다가 높다 = 의미적 유사도에 더 높은 가중치**

```
λ = 0.9 (권장):
- 의미 90% + 다양성 10%
- 의미 손실 거의 없음
- 실용적이고 안전한 선택

λ = 0.7 (비권장):
- 의미 70% + 다양성 30%
- 의미 손실 11%
- 관련성 낮은 샘플 포함 위험
```

**결론: 높은 λ(0.9~1.0)가 실제로는 더 좋습니다.**

---

## 🎯 슬라이드 형식

```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
슬라이드 1: 문제 정의
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

❌ 순수 벡터 검색의 한계

쿼리: "주말에 뭐 할 거야?"
결과: 주말에, 주말에, 주말에, 주말엔...

→ 의미는 유사하지만 표현이 단조로움
→ LLM이 다양한 말투를 학습하기 어려움

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
슬라이드 2: 해결 방법
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

✅ MMR 알고리즘 적용

MMR Score = λ × 의미유사도 - (1-λ) × 다양성

λ = 0.9 선택
• 의미적 유사도 90%
• 표현 다양성 10%

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
슬라이드 3: 파라미터 최적화
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

λ 값 비교 실험

┌────┬──────────┬──────────┐
│ λ  │ 의미유사도 │ 표현다양성 │
├────┼──────────┼──────────┤
│1.0 │ 0.5924   │ 70%      │
│0.9 │ 0.5878↓  │ 60%✅    │
│0.8 │ 0.5574↓↓ │ 30%      │
│0.7 │ 0.5273↓↓↓│ 10%      │
└────┴──────────┴──────────┘

최적값: λ = 0.9
• 의미 손실 0.8% (거의 없음)
• 표현 다양성 14.3% 개선

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
슬라이드 4: 결과
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

Before (λ=1.0):
주말에, 주말동안, 주말에, 주말에...
→ 단조로운 표현

After (λ=0.9):
주말에, 주말동안, 저녁으로, 매주...
→ 다양한 표현

✅ 의미는 유지하면서 표현만 다양화

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
슬라이드 5: 학습 내용
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📚 핵심 학습

1. MMR 알고리즘의 구조와 원리 이해
2. 파라미터 튜닝의 중요성 체험
3. 다양성-관련성 트레이드오프 경험
4. 정량적 평가를 통한 최적값 도출

💡 인사이트

• 1536차원 벡터는 정상 작동
• "첫 글자 일치"는 한국어 특성
• 높은 λ(0.9)가 실제로는 더 좋음
• 실제 프로덕션 적용 가능한 결과

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

## 📁 참고 파일

- 람다 비교 스크립트: `src/scripts/compare-lambda-values.ts`
- MMR 전후 비교: `src/scripts/compare-before-after-mmr.ts`
- 상세 문서: `docs/PRESENTATION_METRICS.md`

---

## 🎤 발표 시 예상 질문과 답변

### Q1: "왜 개선율이 8%밖에 안 되나요?"

**A:**
```
λ=0.9는 의미적 유사도를 우선시하는 설정입니다.
만약 다양성을 더 높이고 싶다면 λ=0.7을 사용할 수 있지만,
그러면 의미적 유사도가 11% 하락합니다.

우리 프로젝트의 목표는 "사용자 말투 모방"이므로
의미적 유사도가 최우선이고, 표현 다양성은 부가적입니다.
따라서 λ=0.9가 최적입니다.
```

### Q2: "첫 글자가 같은 게 왜 문제인가요?"

**A:**
```
첫 글자가 같은 것 자체는 문제가 아닙니다.
오히려 의미적으로 유사한 문장들이
같은 단어로 시작하는 것은 자연스러운 현상입니다.

MMR의 목표는 "첫 글자를 다르게 하는 것"이 아니라
"의미는 유지하면서 표현 방식을 다양화하는 것"입니다.

예: "주말에 뭐 해?" → "저녁으로 할까?", "매주 정해진 날마다..."
```

### Q3: "λ=0.7이 더 다양한데 왜 안 쓰나요?"

**A:**
```
λ=0.7은 다양성 85.7%로 매우 높지만,
의미적 유사도가 11% 하락합니다.

이는 쿼리와 관련성이 낮은 샘플이 포함될 위험을 의미합니다.
LLM이 엉뚱한 답변을 생성할 수 있습니다.

따라서 의미 손실이 0.8%에 불과한 λ=0.9가
실용적이고 안전한 선택입니다.
```

---

## ✅ 최종 정리

```
MMR 알고리즘(λ=0.9) 적용 결과:

✅ 성공:
• 의미적 유사도 거의 유지 (-0.8%)
• 표현 다양성 14.3% 개선
• 실제 프로덕션 적용 가능
• 정량적 평가를 통한 최적화

📚 학습:
• MMR 알고리즘 이해
• 파라미터 튜닝 경험
• 트레이드오프 분석
• 벡터 검색 원리 이해

🎯 결론:
의미는 유지하면서 표현만 다양화
→ 사용자 말투 모방에 최적화된 결과
```

---

**추천 발표 시간**: 2~3분
